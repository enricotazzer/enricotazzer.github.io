<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>BrainNotBraining</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <link rel="alternate" type="application/atom+xml" title="Enrico Tazzer Blog" href="/feed.xml">
    </head>
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="index.html">Home</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="about.html">About</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="posts.html">Articles</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="projects.html">Projects</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="feed.xml" target="_blank">RSS</a></li>
                    </ul>
                </div>
            </div>
        </nav>

        <!-- Page Header-->
        <header class="masthead" style="background-image: url('assets/img/shutterstock_635324807.jpg.webp')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>Rischi dell'AI nell'ambito sanitario</h1>
                            <h2 class="subheading"><p>Quali sono le problematiche che possono insorgere nell'utilizzo di questi strumenti in un settore delicato come quello medico-sanitario?</p>
                            <p>Dall'articolo: <a href="https://www.i-jmr.org/2024/1/e53616">"Benefits and Risks of AI in Health Care: Narrative Review"</a></p></h2>
                            <span class="meta">
                                Posted by
                                <a href="about.html">Enrico Tazzer</a>
                                05 Marzo 2025
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <p>L’integrazione dell’AI nell’health care ha il potenziale di trasformare l’industria (come già visto nel primo articolo), ma solleva anche delle preoccupazioni etiche, normative e di sicurezza. Dopo aver visto numerosi benefici possibili negli scorsi articoli, ora ci concentreremo delle problematiche e sui rischi che possono portare questi strumenti nell’industria.</p>
                        <p>L’adozione dell’AI nel settore sanitario è accompagnata da sfide etiche e normative che richiedono particolare attenzione. Queste problematiche spaziano dalla salvaguardia della privacy dei dati del paziente, all’indirizzamento dei bias algoritmici che possono perpetuare disparità dei risultati sanitari. Il mio intendo è quello di illustrare, discutere e farvi pensare ai dilemmi sollevati ultimamente dall’adozione dell’AI in ambito medico e a possibili soluzioni.</p>
                        <h3 class="section-heading">La diagnosi umana verrà superata dalla macchina?</h3>
                        <p>Sebbene l’AI abbia il potenziale per migliorare l’accuratezza delle analisi, non è sempre superiore alla diagnosi umana. Questo perché il medico, grazie alla sua esperienza clinica e capacità di ragionamento logico, può formulare una diagnosi corretta anche in situazioni in cui l’AI ha commesso un errore di previsione.</p>
                        <p>Il vero rischio, a mio parere, è credere che un sistema di AI possa sostituire completamente il giudizio medico. La realtà ci mostra che le prestazioni dell’AI, sebbene costanti, possono essere sia superiori che inferiori a quelle umane a seconda del contesto. Per questo motivo, come sottolineato più volte, l’AI deve essere vista come uno strumento di supporto alla diagnosi e non come un sostituto della mente umana.(almeno finche non riusciremo a far pensare un computer lol).</p>
                        <h3 class="section-heading">Implementazione nel worklflow</h3>
                        <p>Uno dei principali ostacoli alla “rivoluzione dell’AI” in ambito medico è l’integrazione di questi strumenti di supporto nel flusso di lavoro quotidiano dei medici.
                            Questo processo è particolarmente complesso per diversi motivi, tra cui la scarsa formazione dei professionisti sanitari sull’uso di tali sistemi. In ambiti altamente specializzati, come la diagnosi e il trattamento dei tumori, sono emerse due principali criticità:</p>
                        <p>    1.	Limitazioni dello strumento AI stesso, spesso dovute alla mancanza di validazione su dati reali, rendendolo meno affidabile in scenari clinici complessi.</p>
                        <p>    2.	Difficoltà di interpretazione da parte del medico, il quale, senza un’adeguata formazione, potrebbe non essere in grado di comprendere o applicare correttamente i risultati forniti dall’AI.</p>
                        <p>Questo aspetto è aggravato dal fatto che l’addestramento specifico su tali strumenti richiede tempo e risorse, sia per i medici che per le strutture ospedaliere. Nonostante queste sfide, i casi di integrazione dell’AI nel workflow clinico sono ancora limitati. Di conseguenza, i dati attualmente disponibili devono essere valutati con cautela, poiché mancano prove empiriche solide per confermare l’efficacia e la fattibilità di questa integrazione.</p>
                        <h3 class="section-heading">Come gestiamo la privacy?</h3>
                        <p>La rapida comparsa di nuove tecnologia nella sanità, ha scatenato scetticismo per via dei rischi della condivisione dei dati. C’è quindi la necessità di norme pubbliche (mondiali e con urgenza) che governino il flusso dei dati e la loro accessibilità, in modo tale che i pazienti capiscano come e perché i loro dati vengono utilizzati.
                            Si sollevano di conseguenze riguardo la privacy e la sua violazione, per via della capacita dell’AI di anticipare informazioni personali (in qualche modo prevedere, ci sono degli studi che affermano che ad esempio moltissime informazioni personali possano essere inferite dallo scan della retina), i pazienti di conseguenza potrebbero vedere la situazione come una violazione della privacy specialmente se queste “scoperte” vengano rese pubbliche a parti terze.</p>
                        <p>Dal punto di vista etico è quindi necessario rispettare la confidenzialità del paziente e ottenere il suo consenso per l’uso dei dati.
                            I sistemi di AI dovrebbero essere protetti da possibili violazioni dei dati privati, per prevenire danni psicologici e reputazionali dei pazienti, in tal senso i numerosi attacchi al settore sanitario (settore più attaccato dopo quello industriale-tecnologico e dei servizi) dovrebbero farci pensare al quanto è importante questo aspetto.</p>
                        <h3 class="section-heading">Biases</h3>
                        <p>I modelli di machine/deep learning impiegati in ambito sanitario possono essere inclini a presentare bias algoritmici, che possono condurre a predizioni basate su fattori non causali e pregiudizi come genere ed etnia.
                            Questo perché essendo algoritmi progettati e scritti da umani, i pregiudizi e bias umani vengono “inglobati” anche nell’algoritmo, questo perché spesso i dati privilegiano determinate classi sociali o generi rispetto ad altri (non è sorprendente data la nostra società) con il risultato di avere le stesse disparità anche nei risultato dei modelli AI.
                        </p>
                        <h3 class="section-heading">Che succede in caso di errore?</h3>
                        <p>I sistemi di intelligenza artificiale possono commettere errori nella diagnosi e nel trattamento dei pazienti, causando potenziali danni. Rendere questi sistemi responsabili può essere complesso, poiché sorgono questioni di responsabilità legale riguardo agli errori e alla distribuzione delle colpe. La mancanza di spiegazioni nei modelli di deep learning può ostacolare sia la responsabilità legale che la comprensione scientifica, mettendo a rischio la fiducia dei pazienti nel sistema.
                            Determinare la responsabilità per i fallimenti dell’AI è una sfida continua, poiché attribuire la colpa al medico può sembrare ingiusto, mentre ritenerne responsabile lo sviluppatore potrebbe essere troppo distante dal contesto clinico. La questione su chi debba essere ritenuto responsabile quando un sistema di AI fallisce rimane ancora senza una risposta definitiva, nonché un problema etico aperto con opinioni contrastanti e ritengo che la mia opinione sia un’argomento che esca da questo articolo, ma se volete scrivetemi la vostra opinione su LinkedIn (o in privato se avete il contatto :) ).</p>
                        <h3 class="section-heading">Disponibilità e Accessibilità dei Dati</h3>
                        <p>Per addestrare gli algoritmi di intelligenza artificiale nel settore sanitario è necessario un grande volume di dati provenienti da varie fonti. Tuttavia, l’accesso ai dati sanitari può essere complicato a causa della loro frammentazione tra diverse piattaforme e sistemi. La disponibilità di dati nel settore sanitario è limitata e spesso vi è una riluttanza a condividerli tra ospedali. Inoltre, la disponibilità continua di dati per il miglioramento dei sistemi basati su machine learning può essere ostacolata dalla resistenza organizzativa. I progressi tecnologici e lo sviluppo di algoritmi più avanzati possono contribuire a mitigare il problema dei set di dati limitati.</p>
                        
                        <h3 class="section-heading">Social issues</h3>
                        <p>Le idee errate secondo cui l’AI sostituirà i posti di lavoro nel settore sanitario generano scetticismo e avversione nei confronti delle tecnologie basate sull’AI. Tuttavia, l’introduzione dell’AI non implica necessariamente la scomparsa di posti di lavoro, ma piuttosto una loro riorganizzazione. Per superare lo scetticismo e promuovere la fiducia nell’AI, è fondamentale migliorare la comprensione delle sue capacità e favorire un dibattito pubblico informato. Aumentare la consapevolezza sia tra i professionisti sanitari che tra il pubblico è essenziale per gestire le aspettative e affrontare le preoccupazioni legate all’AI.</p>
                        <h3 class="section-heading">Discussione conclusiva</h3>
                        <p>Complessivamente, l’AI offre un enorme potenziale (come abbiamo visto negli scorsi articoli) e continuerà a svolgere un ruolo cruciale nelle future decisioni sanitarie. Se utilizzata con intelligenza, l’AI può ridurre la pressione sul personale sanitario e migliorare la qualità del lavoro, diminuendo gli errori e aumentando la precisione, dando ai pazienti maggiore controllo e consapevolezza sulle proprie decisioni sanitarie e può ridurre i ricoveri evitabili. Inoltre, può ampliare la conoscenza medica generale e migliorare i workflow attuali. Grazie ai suoi vantaggi e alla capacità di guidare lo sviluppo della medicina di precisione, è ampiamente riconosciuta come un’innovazione necessaria in ambito medico.</p>
                        <p>Tuttavia, l’integrazione dell’AI nella sanità presenta delle difficoltà. Acquisire una quantità sufficiente di dati per addestrare algoritmi precisi è una sfida continua, limitato anche dalla diffidenza collettiva in questi strumenti (e direi anche un po di timore generale infondato) soprattuto nella condizione dei propri dati personali, per cui sono necessarie linee guida specifiche nazionali/mondiali per l’adozione sicura e la valutazione delle tecnologie AI, oltre a ricerche approfondite e sulle sue potenzialità e limitazioni. È fondamentale per dimostrate alla popolazione l’utilità effettiva di questi strumenti, condurre studi di implementazioni nella quotidianità dei medici per dimostrare empiricamente i benefici dell’AI nel mondo reale.</p>
                        <p>Dato che l’AI ha un enorme potenziale nonché un’enorme responsabilità nella vita delle persone nel futuro prossimo, ci sono alcuni elementi fondamentali da considerare prima di poterci “affidare” a questi strumenti. Primo, a causa della mancanza di un accordo globale sulla governance dell’AI, potrebbe essere difficile sviluppare sistemi AI applicabili universalmente in tutti i contesti sanitari. Per questo motivo, sarebbe più opportuno concentrarsi su sistemi progettati per l’utilizzo in-loco, ovvero condurre studi e ricerche in una cerchia ristretta di istituti in cui si possa testare l’efficacia pratica di questi modelli. Fondamentalmente, la cura del paziente deve rimanere la priorità, senza farsi trascinare dall’entusiasmo per le nuove tecnologie. È necessario valutare con attenzione la sicurezza e l’affidabilità dei sistemi AI, assicurandosi che vengano utilizzati solo quando la sicurezza che essi portino un vantaggio sia studiato e provato, in modo tale da non rischiare la vita di persone innocenti solo per la mania delle nuove tecnologie.</p>
                        <p>Secondo, l’AI in ambito sanitario deve ancora essere affiancata all’intervento umano. Sebbene l’AI offra vantaggi in termini di velocità e accuratezza, i medici restano indispensabili per compiti cognitivamente complessi e aspetti psicologici della cura. Pertanto, è essenziale formare i medici per integrare l’AI nel loro lavoro, garantendo un equilibrio tra tecnologia e intervento umano.
                            In tal senso non si intenda che diventino degli esperti di AI, sarebbe utopico, nel senso che non devono assolutamente sapere come funziona nello specifico come funziona l’algoritmo, ma bensì che si addestrino i medici all’utilizzo consapevole degli strumenti, avendo le conoscenze necessarie all’interpretare in modo corretto le risposte del sistema, in modo da renderlo un elemento fondamentale nel loro lavoro al pari del camice, i guanti, etc… </p>
                        <p>Un punto cruciale sarà l’aspetto normativo/etico, con questo intendo dire che le organizzazioni internazionali e i governi devono sedersi al banco e decidere che come gestire errori, e vi lascio con dei quesiti di natura etica.
                            Se c’è un errore, chi incolpiamo?
                            Se decidiamo che la colpa è della macchina, come agiamo?
                            Se sbagliasse il medico e da la colpa alla macchina?
                            Una macchina ha la colpa in caso di errore? Se si, incolpiamo il programmatore?
                            Sono chiacchiere da bar ma che prima o poi qualcuno dovrà normare le risposte a queste domande.</p>
                    </div>
                </div>
            </div>
        </article>
        <!-- Footer-->
        <footer class="border-top">
            <footer class="border-top">
                <div class="container px-4 px-lg-5">
                    <div class="row gx-4 gx-lg-5 justify-content-center">
                        <div class="col-md-10 col-lg-8 col-xl-7">
                            <ul class="list-inline text-center">
                                <li class="list-inline-item">
                                    <a href="https://www.linkedin.com/in/enrico-tazzer-a43483340/">
                                        <span class="fa-stack fa-lg">
                                            <i class="fas fa-circle fa-stack-2x"></i>
                                            <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                        </span>
                                    </a>
                                </li>
                                <li class="list-inline-item">
                                    <a href="https://github.com/enricotazzer">
                                        <span class="fa-stack fa-lg">
                                            <i class="fas fa-circle fa-stack-2x"></i>
                                            <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                        </span>
                                    </a>
                                </li>
                            </ul>
                            <div class="small text-center text-muted fst-italic">Copyright &copy; Enrico Tazzer 2024-2025</div>
                        </div>
                    </div>
                </div>
            </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
